<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Michele Buccoli</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<!--<span class="logo"><img src="images/profPic.png" alt="" /></span>-->
						<h1>Michele Buccoli</h1>
						<p>Researcher, Engineer, Geek</p>
						<!--<br />
						built by <a href="https://twitter.com/ajlkn">@ajlkn</a> for <a href="https://html5up.net">HTML5 UP</a>.-->
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<!--<li><a href="#intro" class="active">Introduction</a></li>-->
							<li><a href="#intro">Bio</a></li>
							<li><a href="#theses">Theses</a></li>
							<li><a href="#pub">Publications</a></li>
							<!--<li><a href="#surv">Surveys</a></li>-->
							<li><a href="#res">Projects</a></li>
							<li><a href="#teach">Teaching</a></li>

							<!--<li><a href="#pers">Personal</a></li>-->
							<li><a href="#cont">Contacts</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="intro" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Short bio</h2>
										</header>
										<p>I received my B.Sc. in Computer Engineering in 2010 at the Universit√† di Pisa and my M.Sc. in Computer Engineering (focused on Sound and Music Engineering) in 2013 at the Politecnico di Milano. In 2016 I defended my doctoral thesis titled "Linking signal and semantic representations of musical content for music information retrieval" (download). I then conducted two years of post-doc research at Politecnico di Milano.</p>

										<p>
										My research concerns multimedia information retrieval tasks high-level semantic descriptors, music retrieval by semantic text-based queries and deep learning techniques applied to music information retrieval. <br/>  
										Since 2016 I've been working within the European Project WhoLoDancE, focusing on signal processing and machine learning techniques applied to multimodal signals, such as Motion Capture, Video and Music signals, and interaction design by means of VR approaches. <br/>  
										</p>

										<p>Since 2019 I am Senior Design Engineer at bdSound for the development of speech-based solutions based on machine and deep learning. <br/>
										I also co-supervise students for their Master thesis and work as a teaching assistant at Politecnico di Milano.</p>

										



										
										
										<!--<ul class="actions">
											<li><a href="generic.html" class="button">Learn More</a></li>
										</ul>-->
									</div>
									<span class="image"><img src="images/profPic.png" alt="" /></span>
								</div>
							</section>
							<section id="theses" class="main special">
								<header class="major">
									<h2>Theses</h2>
								</header>
								<h3>Proposals</h3>
								<article>
								<p>We are looking for M.Sc. students to conduct their research thesis in bdSound. 
								<br/>
								You will have a unique chance to test your design skills and find the trade-off between the complexity of your solution and the real-time computational feasibility.
								<br/>
								For any question, feel free to contact me.
								<p>
								</article>


								<!--<article>
								<p>
								<strong>A small-footprint architecture for voice activity detection</strong><br>
								Voice interaction is quickly becoming one of the most pervasive
								way to interact with object for the Internet of Things, and one of the new frontiers of Natural Language Processing.
								<br/>
								IoT solution must work with low requirements in terms of power
								and computational resources. One strategy is to start recognizing voice commands (or sending the speech to a cloud service) only when the system recognizes someone is speaking.
								<br/>								
								The goal of this thesis is to create a reliable and high-accuracy voice activity detector (VAD) based on deep learning networks. The final solution will need to comply with strict requirements regarding
								memory and computational footprint<br/>
								</p>
								</article>-->

								<article>
								<p>
								<strong>Real-time speech enhancement with deep learning</strong><br>
								In order to improve voice interaction, bdSound provides a set of solutions for speech enhancement and noise reduction, using
								adaptive filtering and perceptual descriptors of the speech.
								<br/>
								In this situation there is no better filter than our brain, which can extract information even in extreme noise condition, understanding speech signals by focusing on their patterns.
								<br/>
								The goal of this thesis is to mimic this ability by means of a deep learning network, able to automatically recognize speech from a noisy spectrogram, and enhance the corresponding bins.
								Possible architectures include -but are not limited to- denoising autoencoders and generative adversarial network, with an eye to computational and memory requirements.<br/>
								</p>
								</article>


								<h3>Past theses</h3>
								<article><p>
								During the past 5 years I co-supervised a number of M.Sc. studests from the Politecnico di Milano. 
								</p></article>



								<article>
								<p>
								<em>Automatic playlist generation using recurrent neural network</em><br>
								Rosilde Tatiana Irene, July 2018<br>
								<strong>Short abstract</strong> [...] In this study we propose an automatic playlist generation approach which analyzes hand-crafted playlists, understands their structure and generates new playlists accordingly. Our approach draws inspiration from the language modeling techniques, since a playlist can be seen as a textual composition in which the songs play the role of words. [...] To address this task, we have adopted a deep learning architecture, in particular a Recurrent Neural Network, which is specialized in sequence modeling. [...]<br/>
								<a href="https://www.politesi.polimi.it/handle/10589/142101">Read the thesis</a><br/>
								</p>
								</article>



								<article>
								<p>
								<em>Beat tracking using recurrent neural network : a transfer learning approach</em><br>
								Davide Fiocchi, April 2018<br>
								<strong>Short abstract</strong> [...] In this work, we propose an approach to apply transfer learning for beat tracking. We use a deep RNN as the starting network trained on popular music, and we transfer it to track beats of folk music. Moreover, we test if the resultant models are able to deal with highly variable music. In order to evaluate the effectiveness of our approach, we collect a dataset of Greek folk music, and we manually annotate the pieces.<br/>
								<a href="https://www.politesi.polimi.it/handle/10589/139073">Read the thesis</a><br/>
								</p>
								</article>

								<article>
								<p>
								<em>Learning a personalized similarity metric for musical content</em><br>
								Luca Carloni, April, 2018<br>
								<strong>Short abstract</strong> [...] in this thesis we present a hybrid model for personalized similarity modeling that relies on both content-based and user-related similarity information. The goal is to elaborate a metric able to relate content-based and the similarity information provided by the user. [...] We first exploit a non-metric scaling technique to first elaborate a low-dimensional space (or embedding) which fulfills the similarity information provided by the user. Then we exploit a regression technique in order to learn a mapping able to relate content-based information and embedding-related information. [...]<br/>
								<a href="https://www.politesi.polimi.it/handle/10589/139076">Read the thesis</a><br/>
								</p>
								</article>

								<article>
								<p>
								<em>A personalized metric for music similarity using Siamese deep neural networks</em><br>
								Federico Sala, April 2018<br>
								<strong>Short abstract</strong> [...] music similarity is an extremely subjective concept, hence the similarity metric must take into account user's perception and tastes. In this thesis we propose an approach to model a personalized music similarity metric based on a Deep Neural Network. To address the problem of lack of personalized data, we devise a two-stage approach. A first stage for learning a generic music similarity metric relying on a great amount of data. A second stage for customizing it using personalized annotations collected through a survey. [...]<br/>
								<a href="https://www.politesi.polimi.it/handle/10589/139078">Read the thesis</a><br/>
								</p>
								</article>

								<article>
								<p>
								<em>Analysis of musical structure : an approach based on deep learning</em><br>
								Davide Andreoletti, July 2015<br>
								<strong>Short abstract</strong> [...] The purpose of the Music Structure Analysis is to retrieve the structure of songs at the largest temporal scale, i.e., its division in structural parts like the Chorus and the Verse, in automatic fashion. [...] Since the deep learning techniques have proved to be effective in several areas, in this work we investigate on their use in Music Structural Analysis. [...] we use a Deep Belief Network to extract a sequence of descriptors that is successively given as input to several Music Structural Analysis algorithms presented in literature. [...]<br/>
								<a href="https://www.politesi.polimi.it/handle/10589/108756">Read the thesis</a><br/>
								</p>
								</article>

								<article>
								<p>
								<em>A music search engine based on a contextual related semantic model</em><br>
								Alessandro Gallo, April 2014<br>
								<strong>Short abstract</strong> [...] In this work we propose an approach for music high-level description and music retrieval, that we named Contextual-related semantic model. [...] Our method defines different semantic contexts and dimensional semantic relations between music descriptors belonging to the same context. [...] Our model has been integrated in Janas[1], a music search engine based on semantic textual queries. [...]<br/>
								<a href="https://www.politesi.polimi.it/handle/10589/89922">Read the thesis</a><br/>
								</p>
								</article>



							</section>
						<!-- First Section -->
							<section id="pub" class="main special">
								<header class="major">
									<h2>Publications</h2>
								</header>

								<article>
								<p>
								<em>Deep music on air</em> | <a href="https://dl.acm.org/doi/pdf/10.1145/3359852.3359970">Link</a><br>
								Massimiliano Zanoni, Michele Buccoli, Guglielmo Cassinelli, Giorgio Rinolfi<br/>
								Proceedings of the 9th International Conference on Digital and Interactive Arts, 2019<br/>
								</p>
								</article>

								
								<article>
								<p>
								<em>A Presence- and Performance-Driven Framework to Investigate Interactive Networked Music Learning Scenarios</em> | <a href="https://www.hindawi.com/journals/wcmc/2019/4593853/">Link</a><br>
								Stefano Delle Monache, Luca Comanducci, Michele Buccoli, Massimiliano Zanoni, Augusto Sarti, Enrico Pietrocola, Filippo Berbenni, and Giovanni Cospito<br/>
								Wireless Communications and Mobile Computing, 2019<br/>
								</p>
								</article> 
								
								
								<article>
								<p>
								<em>Automatic playlist generation using Convolutional Neural Networks and Recurrent Neural Networks</em> | <a href="http://eusipco2019.org/Proceedings/papers/1570533791.pdf">Link</a><br>
								Rosilde Tatiana Irene, Clara Borrelli, Massimiliano Zanoni, Michele Buccoli, Augusto Sarti<br/>
								Proceedings of the 27th European Signal Processing Conference (EUSIPCO), 2019<br/>
								</p>
								</article> 
								
								<article>
								<p>
								<em>Virtual Reality and Choreographic Practice: The Potential for New Creative Methods</em> | <a href="https://www.bstjournal.com/articles/10.16995/bst.305/">Link</a><br>
								Rosa E. Cisneros, Karen Wood, Sarah Whatley, Michele Buccoli, Massimiliano Zanoni, Augusto Sarti<br>
								Body, Space & Technology 18 (1), 2019	<br/>
								</p>
								</article>
 
								<article>
								<p>
								<em>Three-dimensional mapping of high-level music features for music browsing</em> | <a href="https://ieeexplore.ieee.org/abstract/document/8665368">Link</a><br>
								Stefano Cherubin, Clara Borrelli, Massimiliano Zanoni, Michele Buccoli, Augusto Sarti, Stefano Tubaro<br>
								Proceedings of the International Workshop on Multilayer Music Representation and Processing (MMRP), Milan, Italy, 2019<br/>
								</p>
								</article>


								<article>
								<p>
								<em>Investigating Networked Music Performances in Pedagogical Scenarios for the InterMUSIC Project</em> | <a href="https://dl.acm.org/citation.cfm?id=3299921">Link</a><br>
								Luca Comanducci, Michele Buccoli, Massimiliano Zanoni, Augusto Sarti, Stefano Delle Monache, Giovanni Cospito, Enrico Pietrocola, Filippo Berbenni<br>
								Proceedings of the 23rd Conference of Open Innovations Association (FRUCT), Bologna, Italy, 2018<br/>
								</p>
								</article>

								
								<article>
								<p>
								<em>Time is not on my side: network latency, presence and performance in remote music interaction</em>| <a href="https://www.academia.edu/38284544/Time_is_not_on_my_side_Network_latency_presence_and_performance_in_remote_music_interaction">Link</a><br>								
								Stefano Delle Monache, Michele Buccoli, Luca Comanducci, Augusto Sarti, Giovanni Cospito, Enrico Pietrocola, Filippo Berbenni<br>
								Proceedings of the XXIII Colloquio di Informatica Musicale (CIM), Udine, Italy, 2018<br/>
								</p>
								</article>

								<article>
								<p>
								<em>WhoLoDancE: Whole-body Interaction Learning for Dance Education</em><br>
								Anna Rizzo, Katerina El Raheb, Sarah Whatley, Rosa Maria Cisneros, Massimiliano Zanoni, Antonio Camurri, Vladimir Viro, Jean-Marc Matos, Stefano Piana, Michele Buccoli, Amalia Markatzi, Pablo Palacio, Oshri Zohar Even, Augusto Sarti, Yannis Ioannidis, Edwin-Morley Fletcher<br>
								EUROMED International Conference on Digital Heritage, 2018<br/>
								</p>
								</article>


								<article>
								<p>
								<em>Beat tracking using recurrent neural network: a transfer learning approach</em><br>
								Davide Fiocchi, Michele Buccoli, Massimiliano Zanoni, Fabio Antonacci, Augusto Sarti<br>
								Proc. of the 26th European Signal Processing Conference (EUSIPCO), 2018<br/>
								</p>
								</article>

								<article>
								<p>
								<em>Using multi-dimensional correlation for matching and alignment of MoCap and video signals</em><br>
								Michele Buccoli, Bruno Di Giorgi, Massimiliano Zanoni, Fabio Antonacci, Augusto Sarti<br>
								Proceedings of the IEEE 19th International Workshop on Multimedia Signal Processing (MMSP), Luton, United Kingdom, 2017<br/>
								<strong>The paper won the Top-10% award</strong>
								</p>
								</article>


								<article>
								<p>
								<em>Unsupervised feature learning for Music Structural Analysis
								</em><br>
								Michele Buccoli, Davide Andreoletti, Massimiliano Zanoni, Augusto Sarti, Stefano Tubaro<br>
								Proceedings of 24th European Signal Processing Conference (EUSIPCO), Budapest, Hungary, 2016
								</p>
								</article>

								<article>
								<p>
								<em>A higher-dimensional expansion of affective norms for English terms for music tagging
								</em><br>
								Michele Buccoli, Massimiliano Zanoni, Gy√∂rgy Fazekas, Augusto Sarti, Mark Sandler and Stefano Tubaro<br>
								Proceedings of 17th International Society for Music Information Retrieval Conference (ISMIR), New York City, USA, 2016
								</p>
								</article>

								<article>
								<p>
								<em>A Dimensional Contextual Semantic Model For Music Description And Retrieval
								</em><br>
								Michele Buccoli, Alessandro Gallo, Massimiliano Zanoni, Augusto Sarti, Stefano Tubaro<br>
								DMRN+10: Digital Music Research Network One-day Workshop 2015, London, UK, 2015
								</p>
								</article>

								<article>
								<p>
								<em>Feature-Based Analysis of the Effects of Packet Delay on Networked Musical Interactions
								</em><br>
								Cristina Emma Margherita Rottondi, Michele Buccoli, Massimiliano Zanoni, Dario Garao, Giacomo Verticale, Augusto Sarti<br>
								Journal of the Audio Engineering Society 63 (11), 864-875
								</p>
								</article>


								<article>
								<p>
								<em>An Unsupervised Approach To The Semantic Description Of The Sound Quality Of Violins</em><br>
								Michele Buccoli, Massimiliano Zanoni, Francesco Setragno, Augusto Sarti, Fabio Antonacci<br>
								European Signal Processing Conference (EUSIPCO), Nice, France, 2015
								</p>
								</article>

								<article>
								<p>
								<em>A Dimensional Contextual Semantic Model For Music Description And Retrieval</em><br>
								Michele Buccoli, Assandro Gallo, Massimiliano Zanoni, Augusto Sarti, Stefano Tubaro<br>
								IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brisbane, Australia, 2015
								</p>
								</article>

								<article>
								<p>
								<em>Unsupervised Feature Learning For Bootleg Detection Using Deep Learning Architectures</em><br>
								Michele Buccoli, Paolo Bestagini, Massimiliano Zanoni, Augusto Sarti, Stefano Tubaro<br>
								IEEE International Workshop on Information Forensics and Security (WIFS), Atlanta, USA, 2014
								</p>
								</article>

								<article>
								<p>
								<em>A Music Search Engine Based Of Semantic Text-query Query</em><br>
								Michele Buccoli, Massimiliano Zanoni, Augusto Sarti, Stefano Tubaro<br>
								in Proceedings of the 15th international workshop on multimedia signal processing - MMSP 2013 - September 30 - October 02, 2013, Pula (Sardinia), Italy
								</p>
								</article>

							</section>

						<!-- Get Started -->
							<section id="res" class="main special">
								<header class="major">
									<h2>Projects</h2>
								</header>
								<div class="content">
									<div class="project">	
										<img src="images/wholodance.png" alt="" class="project_image"/>
										<div class="project_content">	
										<h3>WhoLoDance</h3>
										<p>Wholodance is a Horizon2020 European project that aims at developing and applying breakthrough technologies to Dance Learning in order to achieve results that will have relevant impacts on numerous targets including, but not limited to, the dance practitioners ranging from Researchers and Professionals to Dance Students and the Interested Public.</p>
										<ul class="actions">
										<li><a href="www.wholodance.eu" class="button">Learn More</a></li></ul>
										</div>
										
									</div>
									<div class="project">										
										<img src="images/NMP.png" alt="" class="project_image"/>
										<div class="project_content">											
										<h3>Intermusic</h3>
										<p>Intermusic is a development project carried out on the basis of a strategic partnership between European Music Higher Education Institutions. For the Intermusic project, I conducted several perceptual test at Conservatorio di Milano to assess how latency affect remote music performances.
										This project is financed through the Erasmus+ Italian National Agency in the framework of the Key Action 2.</p>
										<ul class="actions">
										<li><a href="http://intermusicproject.eu/index.php/chi-siamo/" class="button">Learn more</a></li></ul>
										</div>
										
									</div>
									<!--<div class="project">										
										<img src="images/NMP.png" alt="" class="project_image"/>
										<div class="project_content">											
										<h3>Networked Music Performance</h3>
										<p>Networked Music Performance (NMP) concerns the possibility of playing live music with other people via low-delay networks. Beyond the delay of the network, other factors may affect the quality of the music performance. This research aims at finding such factors and parametrize their effect on the overall quality of the performance.</p>
										<ul class="actions">
										<li><a href="./netmusic" class="button">Scores and results</a></li></ul>
										</div>
										
									</div>-->
							    </div>
							</section>


							<div class="null">									
							</div>
							<section id="teach" class="main special">
									<header class="major">
									<h2>Teaching</h2>
									</header>
								
									<div class="teaching_class">	
									<h3>Teaching assistant for Creative Computing and Programming course</h3>
									<p>A.Y 2019/2020;  <br/>
									The workshop focuses on technologies and methodologies to quick develop solutions to enrich artistic performances.<br> 
									The course was taught in English.</p>
										<ul class="actions">
										<li><a href="https://beep.metid.polimi.it/web/2019-20-creative-programming-and-computing-music-and-acoustic-engineering-/" class="button">Beep Portal</a></li></ul>
									</div>
								
									<div class="teaching_class">	
									<h3>Teaching assistant for the Information Retrieval and Data Mining course</h3>
									<p>A.Y 2015/2016; 2016/2017; 2017/2018; 2018/2019<br/>
									M.Sc. in Computer Engineering - Politecnico di Milano <br/>
									The course was taught in English.</br>
									You can find the material of the course by connecting to the beep portal and logging in with your PoliMI credentials.</p>
										<ul class="actions">
										<li><a href="https://beep.metid.polimi.it/" class="button">Beep Portal</a></li></ul>

									</div>

									<div class="teaching_class">	
									<h3>Organizer and Teacher of the workshop  Creative Computing for Artistic Performances</h3>
									<p>A.Y 2017/2018 <br/>
									B.Sc. and M.Sc. in Engineering - Politecnico di Milano <br/>
									</p>	
									</div>


									<div class="teaching_class">	
									<h3>Exercizes on Multimedia Signal Processing, 1st module</h3>
									<p>A.Y 2014/2015; 2016/2017; 2017/2018; 2018/2019 <br/>
									M.Sc. in Computer Engineering - Politecnico di Milano <br/>
									The course was taught in English.</p>
										<ul class="actions">
										<li><a href="./MMSP/" class="button">Slides and Scripts</a></li></ul>
									</div>
									<div class="teaching_class">	
									<h3>Matlab Tutoring</h3>
									<p>A.Y 2014/2015 <br/>
									M.Sc. in Computer Engineering - Como Campus Politecnico di Milano <br/>
									The course was taught in English.</p>
									</div>
							</section>

							<div class="null">									
							</div>
							<!--
							<section id="pers" class="main special">
								<header class="major">
									<h2>Personal</h2>
								</header>
								<div class="content">
									<p>I am a mild hackathon enthusiast: I
										try to attend as many as I can, if I like the mood. Mood that I like: "we want to know smart and creative people, we want them to know with each other, possibly having fun and learning stuff. If at the end there are some good ideas, let's talk". Spirit that I like "you must use the APIs I provide, and stick with the goal I decide. Then I am going to steal your idea and pay you peanuts".
									</p>
									<p>
									</p>
							    </div>
							</section>

							<div class="null">									
							</div>-->
					</div>

				<!-- Footer -->
					<footer id="footer">

						<section id="cont">
							<h2>Contacts</h2>
							<dl class="alt">
								<!--<dt>Address</dt>
								<dd>Via Giuseppe Ponzio 34/5, 20133 Milano - Italy</dd>
								<dt>Phone</dt>
								<dd>+39 02 2399 9653</dd>-->								
								<dt>Email</dt>
								<dd><a href="#">michele.buccoli[at]outlook.it</a></dd>
								<dt>Skype</dt>
								<dd>live:m.buccoli</dd>
								<div class="cont_one_column">
									</div>
							</dl>
							<ul class="icons cont_one_column">
								<li><a href="http://scholar.google.it/citations?user=UXR-R4IAAAAJ" class="icon fa-google alt"><span class="label">Google</span></a></li>
								<li><a href="http://www.linkedin.com/in/michelebuccoli" class="icon fa-linkedin alt"><span class="label">Linkedin</span></a></li>
								<li><a href="https://github.com/mbuccoli" class="icon fa-github alt"><span class="label">GitHub</span></a></li>
								<li><a href="http://www.twitter.com/michele_dec" class="icon fa-twitter alt"><span class="label">Twitter</span></a></li>
							
								
							
							</ul>

							
						</section>
 						<section class="other_contacts">
 						<h2 class="hide_contacts">Contacts</h2>
						<dl class="alt">
								<!--<dt>Skype</dt>
								<dd>live:m.buccoli</dd>-->								
							</dl>
							<ul class="icons">
								<li><a href="http://scholar.google.it/citations?user=UXR-R4IAAAAJ" class="icon fa-google alt"><span class="label">Google</span></a></li>
								<li><a href="http://www.linkedin.com/in/michelebuccoli" class="icon fa-linkedin alt"><span class="label">Linkedin</span></a></li>
								<li><a href="https://github.com/mbuccoli" class="icon fa-github alt"><span class="label">GitHub</span></a></li>
								<li><a href="http://www.twitter.com/michele_dec" class="icon fa-twitter alt"><span class="label">Twitter</span></a></li>
								
								
								<!-- <li><a href="#" class="icon fa-facebook alt"><span class="label">Facebook</span></a></li> 
								<li><a href="#" class="icon fa-skype alt"><span class="label">Skype</span></a></li>
								<li><a href="#" class="icon fa-instagram alt"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon fa-dribbble alt"><span class="label">Dribbble</span></a></li>-->
							</ul>

						</section>
						<!-- <section>
							<h2>Aliquam sed mauris</h2>
							<p>Sed lorem ipsum dolor sit amet et nullam consequat feugiat consequat magna adipiscing tempus etiam dolore veroeros. eget dapibus mauris. Cras aliquet, nisl ut viverra sollicitudin, ligula erat egestas velit, vitae tincidunt odio.</p>
							<ul class="actions">
								<li><a href="generic.html" class="button">Learn More</a></li>
							</ul>
						</section> -->


						<p class="copyright">&copy; Michele Buccoli. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
